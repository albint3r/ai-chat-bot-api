{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e906a66a-77c5-42c4-8d1b-a4ac4e806147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip uninstall -y llama-index transformers langchain-core langchain-openai langchain pypdf pinecone-client grandalf trulens_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb8c0b-d859-434d-8cb7-b2ba624ce793",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install langchain-core\n",
    "!pip install langchain-openai\n",
    "!pip install langchain\n",
    "!pip install pypdf\n",
    "!pip install pinecone-client\n",
    "!pip install grandalf\n",
    "!pip install trulens_eval\n",
    "!pip install llama-index \n",
    "!pip install llama_index \n",
    "# !pip install trulens_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d053bb-087e-4044-84e0-ef6e2a2ad5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b47051e-baad-40d5-90e9-a1973a245dec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "import pinecone\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableSerializable, RunnableParallel, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "# Llama\n",
    "from llama_index import Document\n",
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.vector_stores import PineconeVectorStore\n",
    "from llama_index import GPTVectorStoreIndex, StorageContext, ServiceContext\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index import VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac527ef4-a5d4-4cad-b0aa-55be85ae7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_AI_API_KEY = \"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\"\n",
    "PINECONE_AI_API_KEY = \"ab81ed71-359c-4b1a-a9a2-1a0d82449fda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18b539bf-7531-4bee-be88-7aa19687a223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"OPENAI_API_KEY\"] = OPEN_AI_API_KEY\n",
    "# import openai\n",
    "# openai.api_key = OPEN_AI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2483cc-2ab2-4169-bf9d-959dd8e8e451",
   "metadata": {},
   "source": [
    "# Create The Index Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "077c6292-1a65-47ff-9c32-cc2b9133f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'tobecv2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3316a195-18fd-42cc-bc6c-df5db139e864",
   "metadata": {},
   "source": [
    "### Get CSV with Langchain\n",
    "Because the langain hub dont work I will use the langchain CSV loader.\n",
    "After this I will parse in the Llama Documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ef62bdc-2922-4d9f-847b-f8a650019e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# This a response from this post: https://github.com/langchain-ai/langchain/issues/6961\n",
    "class LlamaCSVLoader:\n",
    "    \"\"\"Loads a CSV file into a list of documents.\n",
    "\n",
    "    Each document represents one row of the CSV file. Every row is converted into a\n",
    "    key/value pair and outputted to a new line in the document's page_content.\n",
    "\n",
    "    The source for each document loaded from csv is set to the value of the\n",
    "    `file_path` argument for all doucments by default.\n",
    "    You can override this by setting the `source_column` argument to the\n",
    "    name of a column in the CSV file.\n",
    "    The source of each document will then be set to the value of the column\n",
    "    with the name specified in `source_column`.\n",
    "\n",
    "    Output Example:\n",
    "        .. code-block:: txt\n",
    "\n",
    "            column1: value1\n",
    "            column2: value2\n",
    "            column3: value3\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_path: str,\n",
    "        source_column: Optional[str] = None,\n",
    "        metadata_columns: Optional[List[str]] = None,   # < ADDED\n",
    "        csv_args: Optional[Dict] = None,\n",
    "        encoding: Optional[str] = None,\n",
    "    ):\n",
    "        self.file_path = file_path\n",
    "        self.source_column = source_column\n",
    "        self.encoding = encoding\n",
    "        self.csv_args = csv_args or {}\n",
    "        self.metadata_columns = metadata_columns        # < ADDED\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        \"\"\"Load data into document objects.\"\"\"\n",
    "\n",
    "        docs = []\n",
    "        with open(self.file_path, newline=\"\", encoding=self.encoding) as csvfile:\n",
    "            csv_reader = csv.DictReader(csvfile, **self.csv_args)  # type: ignore\n",
    "            for i, row in enumerate(csv_reader):\n",
    "                content = \"\\n\".join(f\"{k.strip()}: {v.strip()}\" for k, v in row.items())\n",
    "                try:\n",
    "                    source = (\n",
    "                        row[self.source_column]\n",
    "                        if self.source_column is not None\n",
    "                        else self.file_path\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    raise ValueError(\n",
    "                        f\"Source column '{self.source_column}' not found in CSV file.\"\n",
    "                    )\n",
    "                metadata = {\"source\": source, \"row\": i}\n",
    "                # ADDED TO SAVE METADATA\n",
    "                if self.metadata_columns:\n",
    "                    for k, v in row.items():\n",
    "                        if k in self.metadata_columns:\n",
    "                            metadata[k] = v\n",
    "                # END OF ADDED CODE\n",
    "                doc = Document(text=content, extra_info=metadata)\n",
    "                docs.append(doc)\n",
    "\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c899aa-38e9-44c2-bc97-40f3ccd0189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = LlamaCSVLoader(file_path='qa.csv',encoding='utf-8', metadata_columns=['question', 'answer'])\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d61985-cd2b-47c0-b443-50c2f2f7aac4",
   "metadata": {},
   "source": [
    "### CSV Single Row Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8615684-a4b9-4d91-bf0a-d45363233bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elements: 105\n",
      "Type: <class 'llama_index.schema.Document'>\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "\n",
      "Text:\n",
      "question: Háblame sobre tus proyectos más destacados en programación.\n",
      "answer: He creado varias aplicaciones, una de estas es este chatbot con el cual estas hablando. Tengo otras apps como un predictor de precios en inmuebles. Una app que genera tus entrenamiento (solo debes agregar tus tiempos y equipo), da seguimiento a tu progreso, grafica tus resultados y tiene un timer para ayudarte a la gestion correcta del entrenamiento. También tengo un juego de estrategia multi player basado en un mini juego del Video Juego  Cult Of Lamb.\n",
      "\n",
      "Meta Data:\n",
      "{'source': 'qa.csv', 'row': 10, 'question': 'Háblame sobre tus proyectos más destacados en programación.', 'answer': 'He creado varias aplicaciones, una de estas es este chatbot con el cual estas hablando. Tengo otras apps como un predictor de precios en inmuebles. Una app que genera tus entrenamiento (solo debes agregar tus tiempos y equipo), da seguimiento a tu progreso, grafica tus resultados y tiene un timer para ayudarte a la gestion correcta del entrenamiento. También tengo un juego de estrategia multi player basado en un mini juego del Video Juego  Cult Of Lamb.'}\n"
     ]
    }
   ],
   "source": [
    "single_example = documents[10]\n",
    "print(f'Total elements: {len(documents)}')\n",
    "print(f'Type: {type(single_example)}')\n",
    "print('*-'*30)\n",
    "print(f'\\nText:\\n{single_example.text}\\n')\n",
    "print(f'Meta Data:\\n{single_example.metadata}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6058dfd-10a1-480c-bfd0-a0c3eed39e8c",
   "metadata": {},
   "source": [
    "# Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "360b02d2-10a2-4af7-8caf-361d42c8b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = OpenAIEmbedding(api_key=OPEN_AI_API_KEY, embed_batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3fd22b-6036-4e18-b980-537fde5c26cb",
   "metadata": {},
   "source": [
    "# Create LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fc6a639-9ca2-4b80-b049-7981e45974a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\",api_key=OPEN_AI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24767ffa-41c0-4cd4-b180-be660faa2643",
   "metadata": {},
   "source": [
    "# Create Index with Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab1f059b-0254-4f7f-8900-5bbbe194f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import PodSpec\n",
    "pc = pinecone.Pinecone(api_key=PINECONE_AI_API_KEY)\n",
    "# pinecone.init(api_key=PINECONE_AI_API_KEY, environment='gcp-starter')\n",
    "if index_name in pc.list_indexes().names():\n",
    "    # Connect to the index\n",
    "    pinecone_index = pc.Index(index_name)\n",
    "    vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
    "    # setup our storage (vector db)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    # setup the index/query process, ie the embedding model (and completion if used)\n",
    "    service_context = ServiceContext.from_defaults(llm=llm,embed_model=embed_model)\n",
    "    index = VectorStoreIndex.from_vector_store(vector_store=vector_store, service_context=service_context)\n",
    "else:\n",
    "    # Fist Create the index. But the db still empty.\n",
    "    pc.create_index(name=index_name, dimension=1536, metric='cosine')\n",
    "    # After the index is create add all the documents\n",
    "    pinecone_index = pc.Index(index_name)\n",
    "    # Connect to the index\n",
    "    vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
    "    # setup our storage (vector db)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    # setup the index/query process, ie the embedding model (and completion if used)\n",
    "    service_context = ServiceContext.from_defaults(llm=llm,embed_model=embed_model)\n",
    "    index = GPTVectorStoreIndex.from_documents(documents, storage_context=storage_context,service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f02cbcff-7f34-447b-8250-c7781ac3e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrival = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81323743-0ada-4efc-bf42-72976b157783",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = retrival.query('Que estudiaste?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5e8bd69-0fd2-4b1f-8816-710eb09eb071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estudié la carrera de psicología, mercadotecnia y programación.\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6842a-342e-4fd5-9f84-447c78c27017",
   "metadata": {},
   "source": [
    "# Create evaluation Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee603a47-09a8-4e76-a0ff-d4210b0adaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Qué estudisaste?\n",
      "¿Cuántos años tienes progrando en python?\n",
      "¿Cuáles son tus proyectos en la industria de salud?\n",
      "¿Qué proyectos tienes en Machine Learning?\n",
      "¿Qué proyectos tienes en AI?\n",
      "¿Qué proyectos sabes hacer en criptos?\n",
      "¿Qué aplicaciones has hecho en flutter?\n",
      "¿Sabes usar FastApi?\n",
      "¿Sabes Usar Docker?\n",
      "¿Cuántos años tienes programando?\n"
     ]
    }
   ],
   "source": [
    "eval_questions = []\n",
    "with open('test_questions.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73f72bb5-ac64-4975-971b-c1f56e9d8c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_index 0.8.29post1 or above is required for instrumenting llama_index apps. Please install it before use: `pip install llama_index>=0.8.29post1`.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LLM' from 'llama_index.llms.base' (E:\\base_code\\ai-chat-bot-api\\.venv\\Lib\\site-packages\\llama_index\\llms\\base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tru\n\u001b[0;32m      2\u001b[0m tru \u001b[38;5;241m=\u001b[39m Tru()\n\u001b[0;32m      3\u001b[0m tru\u001b[38;5;241m.\u001b[39mreset_database()\n",
      "File \u001b[1;32mE:\\base_code\\ai-chat-bot-api\\.venv\\Lib\\site-packages\\trulens_eval\\__init__.py:96\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtru_custom_app\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m instrument\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtru_custom_app\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TruCustomApp\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtru_llama\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TruLlama\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrulens_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthreading\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TP\n\u001b[0;32m     99\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTru\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTruBasicApp\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    114\u001b[0m ]\n",
      "File \u001b[1;32mE:\\base_code\\ai-chat-bot-api\\.venv\\Lib\\site-packages\\trulens_eval\\tru_llama.py:44\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseComponent\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# LLMs\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLM \u001b[38;5;66;03m# subtype of BaseComponent\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseQueryEngine\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LLM' from 'llama_index.llms.base' (E:\\base_code\\ai-chat-bot-api\\.venv\\Lib\\site-packages\\llama_index\\llms\\base.py)"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44791777-c2cb-4d92-9ec6-3562461d8d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
