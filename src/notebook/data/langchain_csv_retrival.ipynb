{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd20b321-aecf-44d8-b838-0002ab1a6dec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (0.9.40)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (0.6.3)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (2023.12.2)\n",
      "Requirement already satisfied: httpx in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (0.26.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (1.5.9)\n",
      "Requirement already satisfied: networkx>=3.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (1.26.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (1.6.1)\n",
      "Requirement already satisfied: pandas in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (0.5.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (4.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from llama-index) (0.9.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.3.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from deprecated>=1.2.9.3->llama-index) (1.16.0)\n",
      "Requirement already satisfied: click in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index) (4.66.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from openai>=1.1.0->llama-index) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from openai>=1.1.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from openai>=1.1.0->llama-index) (2.5.3)\n",
      "Requirement already satisfied: sniffio in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from openai>=1.1.0->llama-index) (1.3.0)\n",
      "Requirement already satisfied: certifi in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from httpx->llama-index) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from httpx->llama-index) (1.0.2)\n",
      "Requirement already satisfied: idna in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from httpx->llama-index) (3.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index) (2.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from dataclasses-json->llama-index) (3.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pandas->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pandas->llama-index) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pandas->llama-index) (2023.4)\n",
      "Requirement already satisfied: packaging>=17.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index) (2.14.6)\n",
      "Requirement already satisfied: six>=1.5 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index) (1.16.0)\n",
      "Requirement already satisfied: colorama in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from tqdm->nltk<4.0.0,>=3.8.1->llama-index) (0.4.6)\n",
      "Requirement already satisfied: langchain-core in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (0.1.8)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core) (4.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core) (0.0.77)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core) (2.5.3)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core) (8.2.3)\n",
      "Requirement already satisfied: idna>=2.8 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from anyio<5,>=3->langchain-core) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from anyio<5,>=3->langchain-core) (1.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-core) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-core) (2023.11.17)\n",
      "Requirement already satisfied: langchain-openai in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-openai) (0.1.8)\n",
      "Requirement already satisfied: numpy<2,>=1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-openai) (1.26.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.6.1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-openai) (1.6.1)\n",
      "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-openai) (0.5.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (0.0.77)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (2.5.3)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.6.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.6.1->langchain-openai) (0.26.0)\n",
      "Requirement already satisfied: sniffio in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.6.1->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.6.1->langchain-openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.6.1->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: idna>=2.8 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain-openai) (3.6)\n",
      "Requirement already satisfied: certifi in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain-openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.6.1->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.7->langchain-openai) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.7->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.7->langchain-openai) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.7->langchain-openai) (2.1.0)\n",
      "Requirement already satisfied: colorama in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.6.1->langchain-openai) (0.4.6)\n",
      "Requirement already satisfied: langchain in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.9 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain) (0.0.10)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain) (0.1.8)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain) (0.0.77)\n",
      "Requirement already satisfied: numpy<2,>=1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain) (1.26.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain) (2.5.3)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: pypdf in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: pinecone-client in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pinecone-client) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.4 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pinecone-client) (6.0.1)\n",
      "Requirement already satisfied: loguru>=0.5.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pinecone-client) (0.7.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pinecone-client) (4.9.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pinecone-client) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pinecone-client) (2.1.0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pinecone-client) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from pinecone-client) (1.26.3)\n",
      "Requirement already satisfied: colorama>=0.3.4 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (0.4.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\base_code\\ai-chat-bot-api\\.venv\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2023.11.17)\n",
      "Collecting grandalf\n",
      "  Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 0.0/41.8 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/41.8 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 20.5/41.8 kB 217.9 kB/s eta 0:00:01\n",
      "     -------------------------------------- 41.8/41.8 kB 289.6 kB/s eta 0:00:00\n",
      "Collecting pyparsing (from grandalf)\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "   ---------------------------------------- 0.0/103.1 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 61.4/103.1 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 103.1/103.1 kB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pyparsing, grandalf\n",
      "Successfully installed grandalf-0.8 pyparsing-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index\n",
    "!pip install langchain-core\n",
    "!pip install langchain-openai\n",
    "!pip install langchain\n",
    "!pip install pypdf\n",
    "!pip install pinecone-client\n",
    "!pip install grandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57771822-b4a5-4ea7-82f1-48fd36bee067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "import pinecone\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableSerializable, RunnableParallel, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d327aef4-77ef-4808-90ed-1f9dc10f614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_AI_API_KEY = \"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\"\n",
    "PINECONE_AI_API_KEY = \"ab81ed71-359c-4b1a-a9a2-1a0d82449fda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838180e-2a31-45d2-9659-bd220ac6fc9a",
   "metadata": {},
   "source": [
    "# Create the Index in Pinecone and add Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f5dffb-1222-4b0a-93d4-e79672106797",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'tobecv2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf973b-1786-4423-a44e-f8bcbc1b4a3e",
   "metadata": {},
   "source": [
    "## Load CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb5602bb-3027-4f1c-80bd-4f69b0c4e969",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import Dict, List, Optional\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "\n",
    "# This a response from this post: https://github.com/langchain-ai/langchain/issues/6961\n",
    "class CSVLoader(BaseLoader):\n",
    "    \"\"\"Loads a CSV file into a list of documents.\n",
    "\n",
    "    Each document represents one row of the CSV file. Every row is converted into a\n",
    "    key/value pair and outputted to a new line in the document's page_content.\n",
    "\n",
    "    The source for each document loaded from csv is set to the value of the\n",
    "    `file_path` argument for all doucments by default.\n",
    "    You can override this by setting the `source_column` argument to the\n",
    "    name of a column in the CSV file.\n",
    "    The source of each document will then be set to the value of the column\n",
    "    with the name specified in `source_column`.\n",
    "\n",
    "    Output Example:\n",
    "        .. code-block:: txt\n",
    "\n",
    "            column1: value1\n",
    "            column2: value2\n",
    "            column3: value3\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_path: str,\n",
    "        source_column: Optional[str] = None,\n",
    "        metadata_columns: Optional[List[str]] = None,   # < ADDED\n",
    "        csv_args: Optional[Dict] = None,\n",
    "        encoding: Optional[str] = None,\n",
    "    ):\n",
    "        self.file_path = file_path\n",
    "        self.source_column = source_column\n",
    "        self.encoding = encoding\n",
    "        self.csv_args = csv_args or {}\n",
    "        self.metadata_columns = metadata_columns        # < ADDED\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        \"\"\"Load data into document objects.\"\"\"\n",
    "\n",
    "        docs = []\n",
    "        with open(self.file_path, newline=\"\", encoding=self.encoding) as csvfile:\n",
    "            csv_reader = csv.DictReader(csvfile, **self.csv_args)  # type: ignore\n",
    "            for i, row in enumerate(csv_reader):\n",
    "                content = \"\\n\".join(f\"{k.strip()}: {v.strip()}\" for k, v in row.items())\n",
    "                try:\n",
    "                    source = (\n",
    "                        row[self.source_column]\n",
    "                        if self.source_column is not None\n",
    "                        else self.file_path\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    raise ValueError(\n",
    "                        f\"Source column '{self.source_column}' not found in CSV file.\"\n",
    "                    )\n",
    "                metadata = {\"source\": source, \"row\": i}\n",
    "                # ADDED TO SAVE METADATA\n",
    "                if self.metadata_columns:\n",
    "                    for k, v in row.items():\n",
    "                        if k in self.metadata_columns:\n",
    "                            metadata[k] = v\n",
    "                # END OF ADDED CODE\n",
    "                doc = Document(page_content=content, metadata=metadata)\n",
    "                docs.append(doc)\n",
    "\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "401b6a72-3832-4f96-91ad-e48fb02636ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path='qa.csv',encoding='utf-8', metadata_columns=['question', 'answer'])\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c2e083-43d5-43cd-b228-7f5a3a01f0b6",
   "metadata": {},
   "source": [
    "### CSV Single Row Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61501e01-5c21-4607-9ff0-73dcae8e2c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elements: 105\n",
      "Type: <class 'langchain_core.documents.base.Document'>\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "\n",
      "Page Content:\n",
      "question: Háblame sobre tus proyectos más destacados en programación.\n",
      "answer: He creado varias aplicaciones, una de estas es este chatbot con el cual estas hablando. Tengo otras apps como un predictor de precios en inmuebles. Una app que genera tus entrenamiento (solo debes agregar tus tiempos y equipo), da seguimiento a tu progreso, grafica tus resultados y tiene un timer para ayudarte a la gestion correcta del entrenamiento. También tengo un juego de estrategia multi player basado en un mini juego del Video Juego  Cult Of Lamb.\n",
      "\n",
      "Meta Data:\n",
      "{'source': 'qa.csv', 'row': 10, 'question': 'Háblame sobre tus proyectos más destacados en programación.', 'answer': 'He creado varias aplicaciones, una de estas es este chatbot con el cual estas hablando. Tengo otras apps como un predictor de precios en inmuebles. Una app que genera tus entrenamiento (solo debes agregar tus tiempos y equipo), da seguimiento a tu progreso, grafica tus resultados y tiene un timer para ayudarte a la gestion correcta del entrenamiento. También tengo un juego de estrategia multi player basado en un mini juego del Video Juego  Cult Of Lamb.'}\n"
     ]
    }
   ],
   "source": [
    "single_example = documents[10]\n",
    "print(f'Total elements: {len(documents)}')\n",
    "print(f'Type: {type(single_example)}')\n",
    "print('*-'*30)\n",
    "print(f'\\nPage Content:\\n{single_example.page_content}\\n')\n",
    "print(f'Meta Data:\\n{single_example.metadata}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2985b8-f9ae-427a-b64a-7d12e4b0e782",
   "metadata": {},
   "source": [
    "## Create Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "245b7351-1607-42c1-9bb3-ed71b39ca29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings =  OpenAIEmbeddings(openai_api_key=OPEN_AI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a5115-5f65-45c7-b07c-903b21f068ee",
   "metadata": {},
   "source": [
    "## Create LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b906b6-8b9a-484f-89ee-5814f3529452",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0,api_key=OPEN_AI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a471d1ff-7fd7-4825-b06f-7071ec4a3b80",
   "metadata": {},
   "source": [
    "# Create Index with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a61e57-e067-4c98-9b52-d905a5ce7268",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(api_key=PINECONE_AI_API_KEY, environment='gcp-starter')\n",
    "if index_name in pinecone.list_indexes():\n",
    "    index = pinecone.Index(index_name)\n",
    "    vector_store = Pinecone(index, embeddings, \"text\")\n",
    "else:\n",
    "    # Fist Create the index. But the db still empty.\n",
    "    pinecone.create_index(name=index_name, dimension=1536, metric='cosine')\n",
    "    # After the index is create add all the documents\n",
    "    vector_store = Pinecone.from_documents(documents, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7757f6b-77f0-476f-b74a-72327e95044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f555d1ab-c575-4737-9f26-1ef8664fbb20",
   "metadata": {},
   "source": [
    "## Create a Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5f71a8ec-539a-4c78-891f-4b33cb4beee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fortmat_question_template = \"\"\"Rephrase the question in a clearer and more concise manner in the original language\"\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "\n",
    "re_rank_template = \"\"\"You are an Ai assistant. You Need to re rank-this context responses by the relevance with the question. Only return three Documents..\n",
    "Context:\\n{context}\n",
    "Question:{question}\n",
    "\"\"\"\n",
    "final_response_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, respond 'I dont know'. Do it in the same language of the question\n",
    "{context}\n",
    "Question:{question}\n",
    "Les't Think step by step...\"\"\"\n",
    "alternative_final_response_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, respond 'I dont know'. Do it in the same language of the question\n",
    "{context}\n",
    "Question:{question}\n",
    "Answer:\"\"\"\n",
    "format_question_template = PromptTemplate.from_template(fortmat_question_template)\n",
    "re_rank_template = PromptTemplate.from_template(re_rank_template)\n",
    "final_template = PromptTemplate.from_template(alternative_final_response_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486a7d1f-fe6c-436d-b47e-8f319dddfaf2",
   "metadata": {},
   "source": [
    "## First Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d6935d9d-4b6a-43a2-8e20-ac861df3776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain =  {'context': retriver, 'question': RunnablePassthrough()}| re_rank_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5aca8765-af47-4c9a-af71-6e4fb39fd32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Cuantos anos de experiencia tienes en python?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a125fec-e8a2-4c2c-93af-9ed615176516",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddcc5fc8-eed2-46a4-9169-507c959d3f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"1. Document(page_content='question: ¿Qué lenguajes de programación dominas?\\\\nanswer: Tengo 3 años de experiencia en python, 2 años de experiencia en Dart y 2 años de Experiencia en SQL.', metadata={'answer': 'Tengo 3 años de experiencia en python, 2 años de experiencia en Dart y 2 años de Experiencia en SQL.', 'question': '¿Qué lenguajes de programación dominas?', 'row': 43.0, 'source': 'qa.csv'})\\n\\n2. Document(page_content='question: ¿Has obtenido certificaciones relevantes en programación o en tus áreas de especialización?\\\\nanswer: Tengo la cerficación como desarrollador en python, data science y data visualization.', metadata={'answer': 'Tengo la cerficación como desarrollador en python, data science y data visualization.', 'question': '¿Has obtenido certificaciones relevantes en programación o en tus áreas de especialización?', 'row': 18.0, 'source': 'qa.csv'})\\n\\n3. Document(page_content='question: ¿Puedes proporcionar más detalles sobre tu experiencia con las habilidades y tecnologías mencionadas, como Pandas, Pyplot, Numpy, SkLearn en Python?\\\\nanswer: Tengo todas las habilidades de data science, data analisis y machine learnig. He tenido proyectos donde he tenido que crear scrapers para obtener la información, limpiar la información, analizarla, imputar información faltante, para posterioremente crear un modelo de predicción usando la librería de SkLearn.', metadata={'answer': 'Tengo todas las habilidades de data science, data analisis y machine learnig. He tenido proyectos donde he tenido que crear scrapers para obtener la información, limpiar la información, analizarla, imputar información faltante, para posterioremente crear un modelo de predicción usando la librería de SkLearn. ', 'question': '¿Puedes proporcionar más detalles sobre tu experiencia con las habilidades y tecnologías mencionadas, como Pandas, Pyplot, Numpy, SkLearn en Python?', 'row': 52.0, 'source': 'qa.csv'})\")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c77a3ca-5533-43a6-a9d3-1c56de59a255",
   "metadata": {},
   "source": [
    "### Format Response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4828195-2e0f-4660-a552-eb67c254fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refortma context:\n",
    "docs = response.content.split('Document(')\n",
    "docs.pop(0)\n",
    "str_context = '\\n'.join(f'<<Context #{i}>> {doc}' for i, doc in enumerate(docs, start=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d96478b-c1c0-4697-99ce-d6d3eb0d1eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<<Context #1>> page_content='question: ¿Qué lenguajes de programación dominas?\\\\nanswer: Tengo 3 años de experiencia en python, 2 años de experiencia en Dart y 2 años de Experiencia en SQL.', metadata={'answer': 'Tengo 3 años de experiencia en python, 2 años de experiencia en Dart y 2 años de Experiencia en SQL.', 'question': '¿Qué lenguajes de programación dominas?', 'row': 43.0, 'source': 'qa.csv'})\\n\\n2. \\n<<Context #2>> page_content='question: ¿Has obtenido certificaciones relevantes en programación o en tus áreas de especialización?\\\\nanswer: Tengo la cerficación como desarrollador en python, data science y data visualization.', metadata={'answer': 'Tengo la cerficación como desarrollador en python, data science y data visualization.', 'question': '¿Has obtenido certificaciones relevantes en programación o en tus áreas de especialización?', 'row': 18.0, 'source': 'qa.csv'})\\n\\n3. \\n<<Context #3>> page_content='question: ¿Puedes proporcionar más detalles sobre tu experiencia con las habilidades y tecnologías mencionadas, como Pandas, Pyplot, Numpy, SkLearn en Python?\\\\nanswer: Tengo todas las habilidades de data science, data analisis y machine learnig. He tenido proyectos donde he tenido que crear scrapers para obtener la información, limpiar la información, analizarla, imputar información faltante, para posterioremente crear un modelo de predicción usando la librería de SkLearn.', metadata={'answer': 'Tengo todas las habilidades de data science, data analisis y machine learnig. He tenido proyectos donde he tenido que crear scrapers para obtener la información, limpiar la información, analizarla, imputar información faltante, para posterioremente crear un modelo de predicción usando la librería de SkLearn. ', 'question': '¿Puedes proporcionar más detalles sobre tu experiencia con las habilidades y tecnologías mencionadas, como Pandas, Pyplot, Numpy, SkLearn en Python?', 'row': 52.0, 'source': 'qa.csv'})\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4eea658f-f3b7-4a8a-a8ca-8bdc5a59bbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5347a11-f6aa-4e89-8922-8781588fda33",
   "metadata": {},
   "source": [
    "### Second Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6166e9a9-7404-41c9-b6f3-d49ec7fde031",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain =  {'context': itemgetter(\"title\"), 'question': RunnablePassthrough()} | final_template | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ed4e22-bada-46ce-9099-7f1e1124a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = final_chain.invoke({'context': str_context, 'question': question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf04a1-4b4e-48d2-b5c3-349cba34756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78717d0-87de-498a-8eef-b58cbf0cb386",
   "metadata": {},
   "source": [
    "# Concatenate both chain in one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eb8427-9f28-474f-8971-da3f1958185f",
   "metadata": {},
   "source": [
    "The trik to make available other keys is to put the result in a dictionary to have to possibility to extract the result for each key for example the question or context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b3a3ce64-52c4-4ca4-86a6-7591d2b969ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the complex version, but you can use the cell bellow, it do it the same.\n",
    "chain2 =  (RunnableParallel(context=retriver , question=RunnablePassthrough()) |\n",
    "           {'context': re_rank_template, 'question':  itemgetter(\"question\")} |\n",
    "           {'context': itemgetter(\"context\") |\n",
    "            llm, 'question':  itemgetter(\"question\")} |\n",
    "           final_template |\n",
    "           llm |\n",
    "          StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "985209e1-ec46-42f6-a9ab-81c96dba1a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a first chain to reformat the question\n",
    "chain1 =  format_question_template | llm | StrOutputParser()\n",
    "# Pass the reformat question to the context in the run parallel to insert into the template an get all the documents retrivals\n",
    "chain2 = RunnableParallel(context=chain1 | retriver, question=RunnablePassthrough()) | re_rank_template | llm | StrOutputParser()\n",
    "# Use the retrival to reponse the user questions\n",
    "chain3 =  RunnableParallel(context=chain2 , question=RunnablePassthrough())  | final_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c2c94bf8-9046-4cc7-9214-2225dd9b94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain3.invoke({'question': 'How many years of experience do you have in python?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9467f897-7415-4b6d-a7e7-1e0441f44605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           +---------------------------------+         \n",
      "           | Parallel<context,question>Input |         \n",
      "           +---------------------------------+         \n",
      "                    **               ***               \n",
      "                 ***                    **             \n",
      "               **                         ***          \n",
      "   +----------------+                        **        \n",
      "   | PromptTemplate |                         *        \n",
      "   +----------------+                         *        \n",
      "            *                                 *        \n",
      "            *                                 *        \n",
      "            *                                 *        \n",
      "     +------------+                           *        \n",
      "     | ChatOpenAI |                           *        \n",
      "     +------------+                           *        \n",
      "            *                                 *        \n",
      "            *                                 *        \n",
      "            *                                 *        \n",
      "  +-----------------+                         *        \n",
      "  | StrOutputParser |                         *        \n",
      "  +-----------------+                         *        \n",
      "            *                                 *        \n",
      "            *                                 *        \n",
      "            *                                 *        \n",
      "+----------------------+              +-------------+  \n",
      "| VectorStoreRetriever |              | Passthrough |  \n",
      "+----------------------+              +-------------+  \n",
      "                    **               **                \n",
      "                      ***         ***                  \n",
      "                         **     **                     \n",
      "           +----------------------------------+        \n",
      "           | Parallel<context,question>Output |        \n",
      "           +----------------------------------+        \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                    +----------------+                 \n",
      "                    | PromptTemplate |                 \n",
      "                    +----------------+                 \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                      +------------+                   \n",
      "                      | ChatOpenAI |                   \n",
      "                      +------------+                   \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                   +-----------------+                 \n",
      "                   | StrOutputParser |                 \n",
      "                   +-----------------+                 \n",
      "                             *                         \n",
      "                             *                         \n",
      "                             *                         \n",
      "                +-----------------------+              \n",
      "                | StrOutputParserOutput |              \n",
      "                +-----------------------+              \n"
     ]
    }
   ],
   "source": [
    "chain2.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a096fbc-4e6f-4354-909c-3d62afa6673a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
